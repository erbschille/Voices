---
title: "Voice-hearing, inner speech, and absorption"
author: "Eleanor Schille-Hudson"
date: "2025-02-05"
output: 
  html_document:
    toc: yes
    df_print: paged
    toc_float: yes

---

This rmd file contains analyses for the manuscript *Voice-hearing, inner speech, and absorption: the role of an experiential orientation to the mind* which examines the relationship between inner speech, absorption, and voice hearing in two studies. In Study 1, surveys were administered to undergraduates across five countries (total N = 825). In Study 2, surveys were administered to participants in the US via the online survey platform Prolific (N = 1000).


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=F, warning=F, cache=F, message=F)
```

```{r, include = F}
library(tidyverse)
library(qualtRics)
library(parameters)
library(mediation)
library(lavaan)

select <- dplyr::select
```

# Study 1 

In packet 1, participants filled out the absorption scale and spiritual events items in all five countries. (N=519)

In packet 2, participants filled out both the Launay-Slade voice hearing scale and the VISQ inner voice scale in all five countries (McCarthy-Jones & Fernyhough; only dialogic, evaluative, and other people subscales--did not include condensed speech!). (N=523)

```{r}
## SET UP AND LOADING DATA 

# assigning levels for countries
levels_country <- c("US", "Ghana", "Thailand", "China", "Vanuatu")

# contrasts (effect-coding)
contrasts_country <- cbind("_gh" = c(-1, 1, 0, 0, 0),
                           "_th" = c(-1, 0, 1, 0, 0),
                           "_ch" = c(-1, 0, 0, 1, 0),
                           "_vt" = c(-1, 0, 0, 0, 1))

# loading data from packet 1--In packet 1, participants filled out the absorption scale and spiritual events items (N=519)
d_p1 <- read_csv("d_p1.csv") %>% 
  mutate(country = factor(country, levels = levels_country))

contrasts(d_p1$country) <- contrasts_country

# loading data from packet 2--In packet 2, participants filled out both the Launay-Slade voice hearing scale and the VISQ inner voice scale (McCarthy-Jones & Fernyhough; only dialogic, evaluative, and other people subscales--did not include condensed speech!). (N=523)
d_p2 <- read_csv("d_p2.csv") %>% 
  mutate(country = factor(country, levels = levels_country))

contrasts(d_p2$country) <- contrasts_country
```

```{r}
# creating averaged scores for packet 1 data 

#absorption scores
dp1_a <- d_p1 %>% 
  filter(scale == "absorption") %>% #just absorption questions 
  group_by(subject_id) %>%
  mutate(abs_score = sum(response, na.rm = TRUE)) %>% #getting absorption score for each person 
  select(country, subject_id, abs_score)

#spiritual events scores
dp1_b <- d_p1 %>% 
  filter(scale == "spiritual events (v2)") %>% #just spev questions 
  filter(question_universal %in% c("voice_ears", "voice_mind")) %>%
  group_by(subject_id) %>%
  mutate(voice_score = sum(response, na.rm = TRUE)) %>% #getting absorption score for each person 
  select(country, subject_id, voice_score)

#joining into a small dataframe with just absorption and spiritual events scores 
dp1_small <- left_join(
  dp1_a, dp1_b, by = join_by(country, subject_id)) %>% 
  distinct()
```

```{r}
# creating averaged scores for packet 2 data 

# VISQ scores (DIALOGIC)
dp2_d <- d_p2 %>%
  filter(subscale_name == "VISQ: Dialogic") %>% #just dialogic subscale inner voice questions
  group_by(subject_id) %>%
  mutate(visq_score_d = sum(response, na.rm = TRUE)) %>% #getting inner voice score for each person
  select(country, subject_id, visq_score_d)

# VISQ scores (OTHER PEOPLE)
dp2_o <- d_p2 %>%
  filter(subscale_name == "VISQ: Other People") %>% #just dialogic subscale inner voice questions
  group_by(subject_id) %>%
  mutate(visq_score_o = sum(response, na.rm = TRUE)) %>% #getting inner voice score for each person
  select(country, subject_id, visq_score_o)

# VISQ scores (EVALUATIVE)
dp2_e <- d_p2 %>%
  filter(subscale_name == "VISQ: Evaluative") %>% #just dialogic subscale inner voice questions
  group_by(subject_id) %>%
  mutate(visq_score_e = sum(response, na.rm = TRUE)) %>% #getting inner voice score for each person
  select(country, subject_id, visq_score_e)

# Launay Slade scores 
dp2_b <- d_p2 %>% 
  filter(subscale == "hallucination_auditory") %>% 
  group_by(subject_id) %>%
  mutate(response = as.numeric(response),
         ls_score = sum(response, na.rm = TRUE)) %>% #getting hearing voices score for each person
  select(country, subject_id, ls_score)

#joining into a small dataframe with just VISQ and Launay Slade scores 
dp2_small <- left_join(
  dp2_d, dp2_b, by = join_by(country, subject_id)) %>% 
  left_join(dp2_e) %>% 
  left_join(dp2_o) %>%
  distinct()
```

N = 217 participants completed both packets 1 and 2 together. For these participants, we have their absorption, VISQ, and Launay-Slade scores. These participants were only in the US, Ghana, and China. 

```{r}
# creating a dataframe of just the participants who completed BOTH packets 1 and 2 

subj_list <- intersect(unique(d_p1$subject_id), unique(d_p2$subject_id)) #getting the IDs of subjects who filled out both packets 

# absorption scores from packet 1
df1<- d_p1 %>% 
  filter(subject_id %in% subj_list) %>% #just participants who did all packets
  filter(scale == "absorption") %>% #just absorption questions 
  group_by(subject_id) %>%
  mutate(abs_score = sum(response, na.rm = TRUE)) %>% #getting absorption score for each person 
  select(country, subject_id, abs_score)

# VISQ scores from packet 2 (DIALOGIC)
df2_d <- d_p2 %>%
  filter(subject_id %in% subj_list) %>% #just participants who did all packets
  filter(subscale_name == "VISQ: Dialogic") %>% #just dialogic subscale inner voice questions
  group_by(subject_id) %>%
  mutate(visq_score_d = sum(response, na.rm = TRUE)) %>% #getting inner voice score for each person
  select(country, subject_id, visq_score_d)

# VISQ scores from packet 2 (OTHER PEOPLE)
df2_o <- d_p2 %>%
  filter(subject_id %in% subj_list) %>% #just participants who did all packets
  filter(subscale_name == "VISQ: Other People") %>% #just dialogic subscale inner voice questions
  group_by(subject_id) %>%
  mutate(visq_score_o = sum(response, na.rm = TRUE)) %>% #getting inner voice score for each person
  select(country, subject_id, visq_score_o)

# VISQ scores from packet 2 (EVALUATIVE)
df2_e <- d_p2 %>%
  filter(subject_id %in% subj_list) %>% #just participants who did all packets
  filter(subscale_name == "VISQ: Evaluative") %>% #just dialogic subscale inner voice questions
  group_by(subject_id) %>%
  mutate(visq_score_e = sum(response, na.rm = TRUE)) %>% #getting inner voice score for each person
  select(country, subject_id, visq_score_e)

# Launay Slade scores from packet 2
df2ls <- d_p2 %>% 
  filter(subject_id %in% subj_list) %>% #just participants who did all packets
  filter(subscale == "hallucination_auditory") %>% 
  group_by(subject_id) %>%
  mutate(response = as.numeric(response),
         ls_score = sum(response, na.rm = TRUE)) %>% #getting hearing voices score for each person
  select(country, subject_id, ls_score)

# joining all scores together into a smaller dataframe 
df123 <- left_join(df1, df2_d) %>%
  left_join(df2ls) %>%
  left_join(df2_e) %>%
  left_join(df2_o) %>%
  distinct() %>% 
  na.omit() %>% #there were 2 participants with na responses for voice hearing and inner voice
  rename(absorption = abs_score, 
         voice_hearing_launayslade = ls_score)
```

## Figure 1 

Fig. 1 from the manuscript shows the relationship between inner speech (measured by the VISQ dialogic subscale) and voice hearing (measured by the five auditory items of the revised Launay-Slade scale) in N=523 undergraduates in five countries. The second figure here is not in the manuscript, but shows the positive relationship between voice hearing and all 3 VISQ subscales. 

```{r, fig.width=12, fig.asp=0.3}
# Voice hearing predicted by VISQ in all five countries -- just dialogic 
correlations <- dp2_small %>%
  group_by(country) %>%
  summarize(correlation = cor(visq_score_d, ls_score, use = "complete.obs")) %>%
  mutate(label = paste0("R = ", round(correlation, 2))) %>%
  ungroup()

dp2_small %>%
  ggplot(aes(x = visq_score_d, y = ls_score)) + 
  geom_point(alpha = 0.7, size = 0.1) + 
  geom_smooth(method = "lm", se = TRUE, alpha = 0.1,
              color = RColorBrewer::brewer.pal(8,"Set2")[1]) +
  facet_wrap(~ country, ncol = 5) +  
  geom_text(
    data = correlations,
    aes(x = Inf, y = Inf, label = label),  # Add correlation labels
    hjust = 1.1, vjust = 1.5,
    inherit.aes = FALSE
  ) +
  #scale_color_brewer(palette = "Set2") +
  labs(title = "Study 1: Voice Hearing Predicted by Inner Speech",
       subtitle = "Grouped by country",
       x = "Inner Speech Score (Dialogic Subscale)",
       y = "Voice hearing (Launay Slade Auditory Items)")


# Voice hearing predicted by VISQ in all five countries--all 3 subscales 
dp2_small %>%
   pivot_longer(cols = c(visq_score_d, visq_score_e, visq_score_o), names_to = "predictor", values_to = "response") %>%
  ggplot(aes(x = response, y = ls_score)) + 
  geom_jitter(aes(color = predictor), 
              height = 0, width = 0.1, alpha = 0.7, size = 0.1) + 
  geom_smooth(aes(group = predictor, color = predictor), 
              method = "lm", se = TRUE, alpha = 0.1) +
  facet_wrap(~ country, ncol = 5) +  
  scale_color_brewer(palette = "Set2") +
  labs(title = "Voice hearing predicted by VISQ, grouped by country",
       x = "Dialogic VISQ score",
       y = "Voice hearing (Launay Slade)")
```

## Figure 2

Fig. 2 from the manuscript shows N=217 participants’ reports of voice-hearing experiences (Launay-Slade scores) plotted against rescaled scores of inner speech (dialogic subscore of VISQ) and absorption. Inner speech and absorption are predictive of voice hearing across diverse cultural settings.

```{r, fig.width=8, fig.asp=0.5}
# Voice hearing predicted by both absorption and inner voice

df123$absorption <- scales::rescale(df123$absorption, scale = T)
df123$visq_score_d <- scales::rescale(df123$visq_score_d, scale = T)

df123 <- df123 %>% rename(inner_speech = visq_score_d)

df123 %>%
  pivot_longer(cols = absorption:inner_speech, names_to = "predictor", values_to = "response") %>%
  mutate(predictor = factor(predictor, levels = c("inner_speech", "absorption"))) %>%
  ggplot(aes(x = response, y = voice_hearing_launayslade)) + 
  geom_jitter(aes(color = predictor), 
              height = 0, width = 0.1, alpha = 0.8, size = 1) + 
  geom_smooth(aes(group = predictor, color = predictor), 
              method = "lm", se = TRUE, alpha = 0.1) +
  facet_wrap(~ country, ncol = 3) +  
  scale_color_brewer(palette = "Set2") +
  labs(title = "Study 1: Voice Hearing Predicted by Inner Speech & Absorption",
       subtitle = "Grouped by country",
       x = "Scaled responses",
       y = "Voice hearing (Launay Slade Auditory Items)",
       color = "Scale")
```

Across samples of undergraduates collected in the US, Ghana, and China (N=217), scores on the revised Launay-Slade Hallucinations scale were positively correlated with dialogic VISQ scores ($\beta$ = 0.45, p<0.001) 

```{r}
m.voice_visq <- lm(
  scale(voice_hearing_launayslade, scale = T) ~ 1 + scale(inner_speech, scale = T) * country, 
  data = df123)

summary(m.voice_visq)
```

and absorption scores ($\beta$=0.48, p<0.001; these standardized beta coefficients and p-values come from separate regression models for each predictor, each including main effects and interactions with country). 

```{r}
#model of just absorption for people who did both 
m.voice_abs <- lm(
  scale(voice_hearing_launayslade, scale = T) ~ 1 + scale(absorption, scale = T) * country, 
  data = df123)

summary(m.voice_abs)
```

We also note that absorption is a predictor of spiritual experiences of all kinds (Luhrmann, Weisman, et al., 2021). In particular, in Study 1, we found that absorption was a significant predictor of spiritual voice-hearing experiences—namely hearing the voice of God or a spirit with their ears or in their mind ($\beta$=0.25, p<0.001).

```{r}
# model of people in packet 1--spiritual events predicted by absorption
m.dp1 <- lm(
  scale(voice_score, scale = T) ~ 1 + scale(abs_score, scale = T) * country, 
  data = dp1_small)

summary(m.dp1)
```


# Study 2

Study 2 is preregistered at https://osf.io/nr9w4

```{r}
# read in data -- voice replication data (vrd)
vrd_raw <- read_survey("study2_data.csv") 
```


```{r}
#Converting responses to correct numeric codes

# RECODING

vrd <- vrd_raw %>% 
  # sense of control -- in general strongly disagree (-3) to strongly agree (3),
     mutate(across(c(sensecntrl_05, sensecntrl_06, sensecntrl_07, sensecntrl_08,
                     sensecntrl_09, sensecntrl_10, sensecntrl_11, sensecntrl_12), ~ case_when(
    . == "Strongly agree" ~ 3,
    . == "Somewhat agree" ~ 2,
    . == "A little agree" ~ 1,
    . == "Neither agree nor disagree" ~ 0,
    . == "A little disagree" ~ -1,
    . == "Somewhat disagree" ~ -2,
    . == "Strongly disagree" ~ -3,
    TRUE ~ NA_real_  # Set NA for missing or unexpected values
  ))) %>% 
  # sense of control -- items 1, 2, 3, and 4 were reverse coded (strongly disagree is 3)
    mutate(across(c(sensecntrl_01, sensecntrl_02, sensecntrl_03, sensecntrl_04), ~ case_when(
    . == "Strongly agree" ~ -3,
    . == "Somewhat agree" ~ -2,
    . == "A little agree" ~ -1,
    . == "Neither agree nor disagree" ~ 0,
    . == "A little disagree" ~ 1,
    . == "Somewhat disagree" ~ 2,
    . == "Strongly disagree" ~ 3,
    TRUE ~ NA_real_  # Set NA for missing or unexpected values
  ))) %>% 
  # need for cognition -- extremely not like me (-2) to extremely like me (2)
    mutate(across(c(cognition_01, cognition_02, cognition_06, cognition_10,
                    cognition_11, cognition_13, cognition_14, cognition_15, cognition_18), ~ case_when(
    . == "Extremely not like me" ~ -2,
    . == "Somewhat not like me" ~ -1,
    . == "Unsure" ~ 0,
    . == "Somewhat like me" ~ 1,
    . == "Extremely like me" ~ 2,
    TRUE ~ NA_real_  # Set NA for missing or unexpected values
  ))) %>% 
  # need for cognition -- items 3, 4, 5, 7, 8, 9, 12, 16, and 17 were reverse coded (extremely not like me is 2)
    mutate(across(c(cognition_03, cognition_04, cognition_05, cognition_07,
                    cognition_08, cognition_09, cognition_12, cognition_16, cognition_17), ~ case_when(
    . == "Extremely not like me" ~ 2,
    . == "Somewhat not like me" ~ 1,
    . == "Unsure" ~ 0,
    . == "Somewhat like me" ~ -1,
    . == "Extremely like me" ~ -2,
    TRUE ~ NA_real_  # Set NA for missing or unexpected values
  ))) %>% 
  # launay slade -- never (0) to almost always (3)
    mutate(across(c(launay01, launay02, launay03, 
                    launay04, launay05, launay07), ~ case_when(
    . == "Never" ~ 0,
    . == "Sometimes" ~ 1,
    . == "Often" ~ 2,
    . == "Almost Always" ~ 3,
    TRUE ~ NA_real_  # Set NA for missing or unexpected values
  ))) %>% 
  # visq-R -- Never (0) to All the time (6), all items except reverse coded ones
    mutate(across(c(visq_01:visq_06, visq_08:visq_14, visq_16:visq_20, visq_22:visq_26), ~ case_when(
    . == "Never" ~ 0,
    . == "Very Rarely" ~ 1,
    . == "Rarely" ~ 2,
    . == "Sometimes" ~ 3,
    . == "Often" ~ 4,
    . == "Very often" ~ 5,
    . == "All the time" ~ 6,
    TRUE ~ NA_real_  # Set NA for missing or unexpected values
  ))) %>% 
  # visq-R -- reverse coded VISQ-R items
    mutate(across(c(visq_07, visq_15, visq_21), ~ case_when(
    . == "Never" ~ 6,
    . == "Very Rarely" ~ 5,
    . == "Rarely" ~ 4,
    . == "Sometimes" ~ 3,
    . == "Often" ~ 2,
    . == "Very often" ~ 1,
    . == "All the time" ~ 0,
    TRUE ~ NA_real_  # Set NA for missing or unexpected values
  ))) %>% 
 # other voice questions -- Never (0) to Very often (4), I don't know counted as missing data
   mutate(across(c(voice_xs:voice_inoe05), ~ case_when(
    . == "Never" ~ 0,
    . == "Once" ~ 1,
    . == "Several times" ~ 2,
    . == "Fairly often" ~ 3,
    . == "Very often" ~ 4,
    TRUE ~ NA_real_  # Set NA for missing or unexpected values
  ))) %>% 
 # absorption -- false (0), true (1)
    mutate(across(c(absorb_01, absorb_02, absorb_03, absorb_04, 
                    absorb_05, absorb_06, absorb_07, absorb_08, 
                    absorb_09, absorb_10, absorb_11, absorb_12, 
                    absorb_13, absorb_14, absorb_15, absorb_16, 
                    absorb_17, absorb_18, absorb_19, absorb_20, 
                    absorb_21, absorb_22, absorb_23, absorb_24, 
                    absorb_25, absorb_26, absorb_27, absorb_28, 
                    absorb_29, absorb_30, absorb_31, absorb_32, 
                    absorb_33, absorb_34), ~ case_when(
    . == TRUE ~ 1,
    . == FALSE ~ 0,
    TRUE ~ NA_real_  # Set NA for missing or unexpected values
  ))) %>% 
 # porosity -- Response options include “It does not happen” (scored as 0), “It might happen” (scored as 1), or “It definitely happens” (scored as 2)
     mutate(across(c(porosity_01, porosity_02, porosity_03, porosity_04,
                     porosity_05, porosity_06, porosity_07, porosity_08,
                     porosity_09, porosity_10, porosity_11, porosity_12,
                     porosity_13, porosity_14), ~ case_when(
      . == "It does not happen" ~ 0,
      . == "It might happen" ~ 1,
      . == "It definitely happens" ~ 2,
      TRUE ~ NA_real_  # Set NA for missing or unexpected values
    ))) 
```


```{r}
# Filtering out people according to exclusion criteria

vrd <- vrd %>% 
  # exclusion criterion 1
  filter(`consent_attn-commit` == "Yes, I will") %>%
  
  # exclusion criterion 2
  filter(sensecntrl_attn == "Strongly agree") %>% # making only people who passed the sense of control attention check 
  filter(absorb_attn == TRUE) %>% 
  
  # exclusion criterion 3
  filter(!(`final_attn-free` %in% c("\"I drive a lot at night. My job has a lot of travel to it. Sometimes people talking…But I can’t tell what they say…just a word here and there. When this first started happening...When I first started driving at night so much...Four or five years ago…it scared the hell out of me. But now I’m used to it. I think I do it because I’m tired and by myself.\"Has something like this ever happened to you?", 
                                    "Evil thoughts can go out into the world like Wi-Fi or a radio and cause bad things to happen to other people.", "good", "T", 
                                    "i dont know", "About a school", 
                                    "I provided information and responded to questions about various topics, including the definition of liberal, a story about a person's economic ascent, Virginia zip codes, and a specific zip code for Kent, Virginia.", "I wrote an essay about what it was like to learn to play the violin."))) %>%
  
  # exclusion criterion 4
  filter(`final_attn-commit` == "Yes, in general I provided thoughtful answers")
```


```{r}
#Calculating people's scores for all the scales.

vrd_scores <- vrd %>%
  rowwise() %>%  # Apply rowwise to perform row-wise operations
  mutate(
    #absorption score
    abs_score = mean(c_across(c(absorb_01, absorb_02, absorb_03, absorb_04,
                                absorb_05, absorb_06, absorb_07, absorb_08,
                                absorb_09, absorb_10, absorb_11, absorb_12,
                                absorb_13, absorb_14, absorb_15, absorb_16,
                                absorb_17, absorb_18, absorb_19, absorb_20,
                                absorb_21, absorb_22, absorb_23, absorb_24,
                                absorb_25, absorb_26, absorb_27, absorb_28,
                                absorb_29, absorb_30, absorb_31, absorb_32,
                                absorb_33, absorb_34)), na.rm = TRUE),
    
    #visq-r dialogic score 2,6,10,13,21
    visq_d_score = mean(c_across(c(visq_02, visq_06, visq_10, visq_13, visq_21)), na.rm = TRUE),  
    #visq-r other people score 3,4,5,12,16
    visq_o_score = mean(c_across(c(visq_03, visq_04, visq_05, visq_12, visq_16)), na.rm = TRUE), 
    #visq-r evaluative score 9,11,17,18,20,23,24
    visq_e_score = mean(c_across(c(visq_09, visq_11, visq_17, visq_18, visq_20, visq_23, visq_24)), na.rm = TRUE),
    #visq old score
    visq_old = mean(c_across(c(visq_01:visq_18))),
    #visq-r full score
    visq_full_score = mean(c_across(c(visq_01:visq_26)), na.rm = TRUE),
    
    #launayslade score -- excluding the one visual question
    launayslade_score = mean(c_across(c(launay01, launay02, launay03, 
                                       launay04, launay05)), na.rm = TRUE),
    #other voices all
    other_voices_score = mean(c_across(c(voice_xs:voice_inoe05)), na.rm = TRUE),
    #other voices spiritual
    other_voices_spiritual_score = mean(c_across(c(voice_spev_voiceears, voice_spev_voicemind, voice_spev_thoughtmi,
                                                voice_pl11)), na.rm = TRUE),
    # sense of control score
    sensecntrl_score = mean(c_across(c(sensecntrl_01, sensecntrl_02, sensecntrl_03, sensecntrl_04,
                                      sensecntrl_05, sensecntrl_06, sensecntrl_07, sensecntrl_08,
                                      sensecntrl_09, sensecntrl_10, sensecntrl_11, sensecntrl_12)), na.rm = TRUE),
    # need for cognition score 
    cognition_score = mean(c_across(c(cognition_01, cognition_02, cognition_06, cognition_10,
                                     cognition_11, cognition_13, cognition_14, cognition_15, cognition_18,
                                     cognition_03, cognition_04, cognition_05, cognition_07, 
                                     cognition_08, cognition_09, cognition_12, cognition_16, cognition_17)), na.rm = TRUE),
    
    # porosity score
    porosity_score = mean(c_across(c(porosity_01, porosity_02, porosity_03, porosity_04, 
                                    porosity_05, porosity_06, porosity_07, porosity_08,
                                    porosity_09, porosity_10, porosity_11, porosity_12,
                                    porosity_13, porosity_14)), na.rm = TRUE), 
    # posey losch score 
    poseylosch_score = mean(c_across(c(voice_pl1, voice_pl2, voice_pl3, voice_pl4a,
                                      voice_pl4b, voice_pl5, voice_pl7, voice_pl8,
                                      voice_pl9, voice_pl10, voice_pl11, voice_pl12, 
                                      voice_pl13, voice_pl14)), na.rm = TRUE)
  ) %>%
  ungroup()
```

```{r}
vrd <- vrd %>% 
  mutate(gender = factor(demo_part1_gender, 
                                    levels = c("Man", "Woman", "Something else (Please feel free to say more below.)")),
         age = as.numeric(demo_part1_age), 
         race = factor(demo_part1_race, 
                                    levels = c("White", "Black or African American", "Hispanic or Latina/o", 
                                               "Central Asian", "East Asian", "Southeast Asian", "South Asian",
                                               "Native Hawaiian or Pacific Islander", "Middle Eastern or North African",
                                               "Native American, American Indian, or Alaska Native", "Some other race or ethnicity (Please feel free to say more below.)")), 
         education = factor(demo_part1_education, 
                                    levels = c("Less than high school", "High school or equivalent (for example, GED)",
                                               "Vocational degree", "Some college", "College degree (AA, BA, BS)", 
                                               "Some graduate school", "Graduate degree (for example, MA, MS, PhD, MD, JD)",
                                               "Something else (Please feel free to say more below.)"))
         )
```

Summary of participants by gender
```{r}
summary(vrd$gender)
```

Summary of participants by age
```{r}
summary(vrd$age)
```

Summary of participants by race
```{r}
summary(vrd$race)
```

Summary of participants by education
```{r}
summary(vrd$education)
```

## Preregistered Analyses 

### Hypothesis 1 

*Inner speech is a significant predictor of voice hearing experiences.*

To test this hypothesis, we will conduct four mixed effects linear regressions, one for each of the three VISQ-R subscales that have been shown to be predictive of voice hearing in past work (namely the  evaluative, dialogic, and other people subscales), as well as a regression for the full Revised Varieties of Inner Speech questionnaire (VISQ-R).  In all models, the outcome of interest will be the participant's score on the Launay Slade hallucination scale. The models will use the following regression formula: Launay slade scale ~ 1 + VISQ-R + (1 | subject ID).  

*(We note that in our preregistration we intended to run mixed-effects models with random intercepts on participants. This proved untenable as we had the same number of participants as observations. Models were run as regressions using the function lm() in the R package stats.)*

```{r}
# dialogic subscale -- REMEMBER ISSUE WITH RANDOM EFFECTS
m.h1_ls_d <- lm(
  scale(launayslade_score, scale = T) ~ 1 + scale(visq_d_score, scale = T), 
  data = vrd_scores)

#summary(m.h1_ls_d)

# evaluative subscale 
m.h1_ls_e <- lm(
  scale(launayslade_score, scale = T) ~ 1 + scale(visq_e_score, scale = T), 
  data = vrd_scores)

#summary(m.h1_ls_e)

# other people subscale 
m.h1_ls_o <- lm(
  scale(launayslade_score, scale = T) ~ 1 + scale(visq_o_score, scale = T), 
  data = vrd_scores)

#summary(m.h1_ls_o)

# full VISQ-R
m.h1_ls_full <- lm(
  scale(launayslade_score, scale = T) ~ 1 + scale(visq_full_score, scale = T), 
  data = vrd_scores)

summary(m.h1_ls_full)
```
We find that hypothesis 1 is confirmed--in each of these models, inner speech is a significant predictor of voice hearing (p<0.001).

### Hypothesis 2

*Absorption is a significant predictor of voice hearing experiences.* 

To test this hypothesis, we will run one mixed effects linear regression in which the outcome of interest will be the participant's score on the Launay Slade hallucination scale. The model will use the following regression formula: Launay Slade scale ~ 1 + absorption + (1 | subject ID).  

```{r}
# SAME ISSUE WITH RANDOM EFFECTS
m.h2_ls_abs <-lm(
  scale(launayslade_score, scale = T) ~ 1 + scale(abs_score, scale = T), 
  data = vrd_scores)

summary(m.h2_ls_abs)
```

We find that hypothesis 2 is confirmed. Absorption is a significant predictor of voice hearing (p<0.001).

### Hypothesis 3

*Inner speech (as measured by VISQ-R) is a mediator of absorption's effect on voice hearing.* 

We will conduct two sets of mediation analyses using the psych package in R (which bootstraps confidence intervals). The first set will include Absorption as the predictor,  the outcome of interest will be the participant's score on the Launay Slade hallucination scale, and the mediating variable will be the participants' Inner Speech score as measured by the VISQ-R. In this set of mediation analyses, we will conduct four analyses total, one for each of the three VISQ-R subscales of interest and one for the full VISQ-R score. The models will use the following formula: psych::mediate(Launay Slade ~ (VISQ-R) + Absorption). These mediation analyses will be considered consistent with our hypothesis in the case that the indirect effect is significant. This will be evaluated via the psych package's significance testing of the bootstrapped indirect effect--meaning that the confidence interval on this effect does not include 0. In the second set of analyses, everything will be kept the same, except the role of predictor and mediator will be reversed. This is in order to determine which direction of mediation is most consistent with the data collected. The models will use the following formula: psych::mediate(Launay Slade ~ (Absorption) + VISQ-R). We will evaluate these models as *not* consistent with our hypothesis by once again using the psych package's significance testing of the bootstrapped indirect effect. We hypothesize that the confidence intervals on this effect will include 0. 

Output here includes Figure 4 from the manuscript. 

```{r}
# setting up df with scaled scores

df_scored_scales <- vrd_scores %>% 
  select(launayslade_score, visq_full_score, visq_d_score, visq_e_score, visq_o_score, other_voices_score, other_voices_spiritual_score, abs_score) %>%
  mutate(
    VoiceHearing = scales::rescale(launayslade_score, scale = T),
    InnerSpeech = scales::rescale(visq_full_score, scale = T),
    visq_d_score = scales::rescale(visq_d_score, scale = T),
    visq_e_score = scales::rescale(visq_e_score, scale = T),
    visq_o_score = scales::rescale(visq_o_score, scale = T),
    other_voices_score = scales::rescale(other_voices_score, scale = T),
    other_voices_spiritual_score = scales::rescale(other_voices_spiritual_score, scale = T),
    Absorption = scales::rescale(abs_score, scale = T)
  )
```

```{r}
# Inner speech as mediator

# ## dialogic subscale 
# m.h3_d_abs <- psych::mediate(launayslade_score ~ (visq_d_score) + abs_score, data = df_scored_scales)
# m.h3_d_abs
# 
# ## evaluative subscale 
# m.h3_e_abs <- psych::mediate(launayslade_score ~ (visq_e_score) + abs_score, data = df_scored_scales)
# m.h3_e_abs
# 
# ## other people subscale
# m.h3_o_abs <- psych::mediate(launayslade_score ~ (visq_o_score) + abs_score, data = df_scored_scales)
# m.h3_o_abs

## full VISQ-R
m.h3_full_abs <- psych::mediate(VoiceHearing ~ (InnerSpeech) + Absorption, data = df_scored_scales)
m.h3_full_abs
```

Part 1 of hypothesis 3 is confirmed--none of the mediation models have bootstrapped indirect effects whose CIs contain 0. That is, all the subscales of the VISQ-R are confirmed as mediators, although the full VISQ-R has the largest mediating effect of absorption on voice hearing. 

```{r}
# Absorption as mediator

# ## dialogic subscale 
# m.h3_abs_d <- psych::mediate(launayslade_score ~ (abs_score) + visq_d_score, data = df_scored_scales)
# m.h3_abs_d
# 
# ## evaluative subscale 
# m.h3_abs_e <- psych::mediate(launayslade_score ~ (abs_score) + visq_e_score, data = df_scored_scales)
# m.h3_abs_e
# 
# ## other people subscale
# m.h3_abs_o <- psych::mediate(launayslade_score ~ (abs_score) + visq_o_score, data = df_scored_scales)
# m.h3_abs_o

## full VISQ-R
m.h3_abs_full <- psych::mediate(launayslade_score ~ (abs_score) + visq_full_score, data = df_scored_scales)
m.h3_abs_full
```

The second part of hypothesis 3 is not confirmed--absorption appears to be a mediator in all these models. 

### Hypothesis 4

*Inner speech and absorption are stronger predictors of spiritual experience than other, less theoretically motivated, predictors.* 

To test this hypothesis, we will conduct a set of mixed effects linear regressions in which the outcome of interest will be the participant's score on the Launay Slade hallucination scale. There will be a total of four regressions, one for each of the VISQ-R subscales and one for the full VISQ-R scale. In each regression, the model will include the following fixed effects: (1) predictor (a 4-level categorical variable encoding the difference between our 4 candidate predictors: scores on the Inner speech scale, Absorption scale, Need for Cognition scale, and Sense of Control, Mastery subscale), score on predictor measure, and all possible interactions. The variable “Predictor” will be coded with the following planned orthogonal contrasts: (A) predictors of interest (Inner speech, Absorption) vs. control scales (Need for Cognition, Sense of Control); (B); measures of inner speech vs. absorption; (C) Need for Cognition vs. Sense of Control. The parameter of primary interest will be the interaction between Predictor Contrast A and Predictor Score, which tests whether our predictors of interest were better predictors of spiritual experience than our control measures were.

```{r}
# setting up orthogonal contrasts for levels (inner speech, absorption, need for cognition, sense of control)
contrasts_hyp <- cbind("_A" = c(1,  1, -1, -1),
                       "_B" = c(1, -1,  0,  0),
                       "_C" = c(0,  0,  1, -1))
```

```{r}
## full VISQ-R

# making nice long data frame and turning predictors into a factor
df_full_long <- vrd_scores %>% 
  mutate(visq_full_score = scales::rescale(visq_full_score, scale = T),
         abs_score = scales::rescale(abs_score, scale = T), 
         cognition_score = scales::rescale(cognition_score, scale = T), 
         sensecntrl_score = scales::rescale(sensecntrl_score, scale = T)) %>%
  pivot_longer(cols = c(visq_full_score, abs_score, cognition_score, sensecntrl_score), names_to = "predictors", values_to = "predictor_scores") %>% 
  mutate(predictors = factor(predictors, 
                             levels = c("visq_full_score", "abs_score", "cognition_score", "sensecntrl_score")))

# setting contrasts
contrasts(df_full_long$predictors) <- contrasts_hyp

# model
m.h4_full <- lm(
   scale(launayslade_score, scale = T) ~ 1 + predictors * predictor_scores #+ (1 | ResponseId) #with random effects, failing to converge?
  ,data = df_full_long)

summary(m.h4_full)


```

The interaction between Predictor A and Predictor Score, which tests whether our predictors of interest were better predictors of spiritual experience
than our control measures were, is the key outcome of interest.

```{r}
# for all subscales

## dialogic subscale 

# making nice long data frame and turning predictors into a factor
df_d_long <- vrd_scores %>% 
  mutate(visq_d_score = scales::rescale(visq_d_score, scale = T),
         abs_score = scales::rescale(abs_score, scale = T), 
         cognition_score = scales::rescale(cognition_score, scale = T), 
         sensecntrl_score = scales::rescale(sensecntrl_score, scale = T)) %>%
  pivot_longer(cols = c(visq_d_score, abs_score, cognition_score, sensecntrl_score), names_to = "predictors", values_to = "predictor_scores") %>% 
  mutate(predictors = factor(predictors, 
                             levels = c("visq_d_score", "abs_score", "cognition_score", "sensecntrl_score")))

# setting contrasts
contrasts(df_d_long$predictors) <- contrasts_hyp

# model
m.h4_d <- lm(
   scale(launayslade_score, scale = T) ~ 1 + predictors * predictor_scores #+ (1 | ResponseId) #with random effects, failing to converge?
  ,data = df_d_long)

#summary(m.h4_d)

## evaluative subscale 

# making nice long data frame and turning predictors into a factor
df_e_long <- vrd_scores %>% 
  mutate(visq_e_score = scales::rescale(visq_e_score, scale = T),
         abs_score = scales::rescale(abs_score, scale = T), 
         cognition_score = scales::rescale(cognition_score, scale = T), 
         sensecntrl_score = scales::rescale(sensecntrl_score, scale = T)) %>%
  pivot_longer(cols = c(visq_e_score, abs_score, cognition_score, sensecntrl_score), names_to = "predictors", values_to = "predictor_scores") %>% 
  mutate(predictors = factor(predictors, 
                             levels = c("visq_e_score", "abs_score", "cognition_score", "sensecntrl_score")))

# setting contrasts
contrasts(df_e_long$predictors) <- contrasts_hyp

# model
m.h4_e <- lm(
   scale(launayslade_score, scale = T) ~ 1 + predictors * predictor_scores #+ (1 | ResponseId) #with random effects, failing to converge?
  ,data = df_e_long)

#summary(m.h4_e)

## other people subscale

# making nice long data frame and turning predictors into a factor
df_o_long <- vrd_scores %>% 
  mutate(visq_o_score = scales::rescale(visq_o_score, scale = T),
         abs_score = scales::rescale(abs_score, scale = T), 
         cognition_score = scales::rescale(cognition_score, scale = T), 
         sensecntrl_score = scales::rescale(sensecntrl_score, scale = T)) %>%
  pivot_longer(cols = c(visq_o_score, abs_score, cognition_score, sensecntrl_score), names_to = "predictors", values_to = "predictor_scores") %>% 
  mutate(predictors = factor(predictors, 
                             levels = c("visq_o_score", "abs_score", "cognition_score", "sensecntrl_score")))

# setting contrasts
contrasts(df_o_long$predictors) <- contrasts_hyp

# model
m.h4_o <- lm(
   scale(launayslade_score, scale = T) ~ 1 + predictors * predictor_scores #+ (1 | ResponseId) #with random effects, failing to converge?
  ,data = df_o_long)

#summary(m.h4_o)

```


## Study 2 Figures

### Figure 3 

```{r, fig.width = 12, fig.asp = 0.3}

# Step 1: Normalize predictors
normalized_data <- vrd_scores %>%
  mutate(
    visq_full_score = scales::rescale(visq_full_score),  # normalizing
    visq_d_score = scales::rescale(visq_d_score),
    visq_e_score = scales::rescale(visq_e_score),
    visq_o_score = scales::rescale(visq_o_score),
    abs_score = scales::rescale(abs_score),
    cognition_score = scales::rescale(cognition_score),
    sensecntrl_score = scales::rescale(sensecntrl_score),
    porosity_score = scales::rescale(porosity_score)
  ) %>%
  rename(
    `Inner Speech` = visq_full_score,
    `Porosity` = porosity_score,
    `Absorption` = abs_score,
    `Need for Cognition` = cognition_score,
    `Sense of Control` = sensecntrl_score
  ) %>%
  gather(predictor, pred_score,
         c(`Inner Speech`, `Porosity`, `Absorption`, `Need for Cognition`, `Sense of Control`)) %>%
  mutate(predictor = factor(predictor, levels = c(
    "Inner Speech", "Absorption", "Porosity",  "Sense of Control", "Need for Cognition"
  )))

# Step 2: Calculate correlations and create labels
correlations <- normalized_data %>%
  group_by(predictor) %>%
  summarize(correlation = cor(pred_score, launayslade_score, use = "complete.obs")) %>%
  mutate(label = paste0("R = ", round(correlation, 2))) %>%
  ungroup()

# Step 3: Plot the data
normalized_data %>%
  ggplot(aes(x = pred_score, y = launayslade_score)) +
  facet_grid(cols = vars(predictor), scales = "free_y") +  # Free y-scale for each predictor
  geom_point(size = 0.1, alpha = 0.5) +
  geom_smooth(aes(color = predictor), method = "lm", show.legend = FALSE) +
  geom_text(
    data = correlations,
    aes(x = Inf, y = Inf, label = label),  # Add correlation labels
    hjust = 1.1, vjust = 1.5,
    inherit.aes = FALSE
  ) +
  theme_bw() +
   scale_color_brewer(palette = "Set2") +
  labs(
    title = "Study 2: Voice Hearing Predicted by Predictors of Interest",
    x = "Predictor Score (Rescaled 0-1)",
    y = "Voice Hearing (Launay Slade Auditory Items)"
  )


```

### Figure 5

```{r, fig.height = 5, fig.asp = 1.2}
# interaction plot 

vrd_scores <- vrd_scores %>%
  mutate(abs_score_level = case_when(
    abs_score < mean(abs_score) - sd(abs_score) ~ "-1 SD",
    abs_score > mean(abs_score) + sd(abs_score) ~ "+1 SD",
    TRUE ~ "Mean"
  ))

vrd_scores %>%
  ggplot(aes(x = visq_full_score, y = launayslade_score, color = abs_score_level)) + 
  geom_line(stat = "smooth", method = "lm", se = FALSE, size = 1) +
  geom_jitter(aes(color = abs_score_level), height = 0.1, width = 0, size = 0.5, alpha = 0.5) +
  labs(
    title = "Study 2: Interaction between Absorption and Inner Speech",
    subtitle = "Predicting Voice Hearing Experiences",
    x = "Inner Speech Score (mean)",
    y = "Voice Hearing score (Launay Slade Auditory Items)",
    color = "Absorption Level"
  ) +
  theme_bw() +
  theme(
    legend.position = "top"
  )
```

## Exploratory Analyses (not preregistered)

### Correlation between Porosity and Voice Hearing

```{r}
# porosity predicts launay slade 
# full VISQ-R
m.ex_ls_por <- lm(
  scale(launayslade_score, scale = T) ~ 1 + scale(porosity_score, scale = T), 
  data = vrd_scores)

summary(m.ex_ls_por)
```

### Interaction between Inner Speech and Absorption

```{r}

m.voice_ls <- lm(
  scale(launayslade_score, scale = T) ~ 1 + scale(visq_full_score, scale = T) * scale(abs_score, scale = T), 
  data = vrd_scores)

summary(m.voice_ls)
```

### Moderated mediation model 

```{r}
vrd_scores_scaled <- vrd_scores %>% 
  mutate(launayslade_score = scale(launayslade_score, scale = T), 
         visq_full_score = scale(visq_full_score, scale = T), 
         abs_score = scale(abs_score, scale = T))

# Moderated Mediation Model (lavaan)
model <- "
  # Path a: IV to Mediator
  visq_full_score ~ a1 * abs_score
  
  # Path b: Mediator to DV, moderated by IV
  launayslade_score ~ b1 * visq_full_score + c1 * abs_score + b2 * visq_full_score:abs_score
  
  # Indirect Effect
  Indirect := a1 * b1
  
  # Direct Effect
  Direct := c1
  
  # Total Effect
  Total := Indirect + Direct
"

fit <- lavaan::sem(model, data = vrd_scores_scaled, se = "bootstrap")
summary(fit, standardized = TRUE)
```

### Prevalence of voice hearing

The proportion of participants who responded more than 'never' to at least one Launay-Slade item: 
```{r}
# launay slade 
ls_great_zero <- sum(vrd_scores$launayslade_score > 0, na.rm = TRUE)
ls_great_zero/975
```

The proportion of participants who responded more than 'never' to at least one Posey Losch item: 
```{r}
# posey losch 
pl_great_zero <- sum(vrd_scores$poseylosch_score > 0, na.rm  = TRUE)
pl_great_zero/975
```

The proporiton of participants who responded more than 'never' to at least one spiritual voice question: 
```{r}
# spiritual experience
#sum(vrd_scores$voice_spev_thoughtmi > 0, na.rm  = TRUE)/975 #a thought in the mind put there by God
#sum(vrd_scores$voice_spev_voicemind > 0, na.rm  = TRUE)/975 #a voice in the mind put there by God
sum(vrd_scores$other_voices_spiritual_score > 0, na.rm = TRUE)/975 #all spiritual voice questions
```







